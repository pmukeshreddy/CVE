{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "decd24f4-6d20-4783-9eec-fe500e498f09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import shutil\n",
    "from pyspark.sql.functions import input_file_name, col, to_timestamp, year\n",
    "\n",
    "USE_OFFLINE = False\n",
    "TARGET_YEAR = 2024\n",
    "zip_destination = \"/tmp/cve/cvelistV5.zip\"\n",
    "extraction_folder = \"/tmp/cve/cvelistV5-main\"\n",
    "\n",
    "os.makedirs(\"/tmp/cve\", exist_ok=True)\n",
    "\n",
    "if not USE_OFFLINE:\n",
    "    github_url = \"https://github.com/CVEProject/cvelistV5/archive/refs/heads/main.zip\"\n",
    "    with urllib.request.urlopen(github_url) as response:\n",
    "        downloaded_data = response.read()\n",
    "    with open(zip_destination, \"wb\") as file:\n",
    "        file.write(downloaded_data)\n",
    "else:\n",
    "    zip_destination = \"/dbfs/FileStore/cvelistV5.zip\"\n",
    "    assert os.path.exists(zip_destination), f\"Missing file: {zip_destination}\"\n",
    "\n",
    "if os.path.exists(extraction_folder):\n",
    "    shutil.rmtree(extraction_folder, ignore_errors=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_destination) as archive:\n",
    "    archive.extractall(\"/tmp/cve/\")\n",
    "\n",
    "cve_json_directory = \"/tmp/cve/cvelistV5-main/cves\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4a3be2b-ffeb-4910-8921-2d33efa255d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import from_json, schema_of_json, col\n",
    "\n",
    "TARGET_YEAR = 2024\n",
    "year_folder = f\"/tmp/cve/cvelistV5-main/cves/{TARGET_YEAR}\"\n",
    "\n",
    "json_data = []\n",
    "\n",
    "for root, directories, files in os.walk(year_folder):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.json'):\n",
    "            full_path = os.path.join(root, filename)\n",
    "            with open(full_path, 'r') as json_file:\n",
    "                json_data.append(json_file.read())\n",
    "\n",
    "pandas_df = pd.DataFrame({'json_string': json_data})\n",
    "spark_temp = spark.createDataFrame(pandas_df)\n",
    "\n",
    "sample_record = json_data[0]\n",
    "inferred_schema = schema_of_json(sample_record)\n",
    "\n",
    "df_raw = spark_temp.select(\n",
    "    from_json(col(\"json_string\"), inferred_schema).alias(\"data\")\n",
    ").select(\"data.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "161fd8e4-aa49-4b86-a05f-df0fdad468d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Total raw records: 38,753\n✓ 2024 records: 32,924\n✓ Null CVE IDs: 0\n✓ Unique CVE IDs: 32924\n✓ All assertions passed!\n\n✓ Table verified: 32,924 records in cve_bronze.records\n+------+------------------------------------+----------------------------+-----------+--------+----------------------+-------------------+----------------+-----------------+--------+-----------+-------------------------------------------------------------------------------------------------------------------------------------------------------+----------------+----------------+--------------------------------------------------------+---------------------------------------------------------------+-------------+\n|format|id                                  |name                        |description|location|createdAt             |lastModified       |partitionColumns|clusteringColumns|numFiles|sizeInBytes|properties                                                                                                                                             |minReaderVersion|minWriterVersion|tableFeatures                                           |statistics                                                     |clusterByAuto|\n+------+------------------------------------+----------------------------+-----------+--------+----------------------+-------------------+----------------+-----------------+--------+-----------+-------------------------------------------------------------------------------------------------------------------------------------------------------+----------------+----------------+--------------------------------------------------------+---------------------------------------------------------------+-------------+\n|delta |cd972f21-7534-405f-beab-8a3a215b4547|workspace.cve_bronze.records|NULL       |        |2025-11-17 03:46:13.87|2025-11-17 03:46:18|[]              |[]               |8       |10056302   |{delta.columnMapping.mode -> name, delta.parquet.compression.codec -> zstd, delta.enableDeletionVectors -> true, delta.columnMapping.maxColumnId -> 73}|3               |7               |[appendOnly, columnMapping, deletionVectors, invariants]|{numRowsDeletedByDeletionVectors -> 0, numDeletionVectors -> 0}|false        |\n+------+------------------------------------+----------------------------+-----------+--------+----------------------+-------------------+----------------+-----------------+--------+-----------+-------------------------------------------------------------------------------------------------------------------------------------------------------+----------------+----------------+--------------------------------------------------------+---------------------------------------------------------------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "bronze_table_name = \"cve_bronze.records\"\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"8\")\n",
    "\n",
    "publication_date = F.col(\"cveMetadata.datePublished\").cast(\"string\")\n",
    "df_with_timestamp = df_raw.withColumn(\"_datePublished_ts\", F.to_timestamp(publication_date))\n",
    "df_2024 = df_with_timestamp.filter(F.year(F.col(\"_datePublished_ts\")) == 2024)\n",
    "\n",
    "total_records = df_raw.count()\n",
    "records_2024 = df_2024.count()\n",
    "null_cve_ids = df_2024.filter(F.col(\"cveMetadata.cveId\").isNull()).count()\n",
    "unique_cve_ids = df_2024.select(\"cveMetadata.cveId\").distinct().count()\n",
    "\n",
    "assert records_2024 >= 30000, f\"Expected at least 30,000 records, got {records_2024:,}\"\n",
    "assert null_cve_ids == 0, f\"Found {null_cve_ids} null CVE IDs\"\n",
    "assert unique_cve_ids == records_2024, f\"Duplicate CVE IDs detected: {records_2024 - unique_cve_ids}\"\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {bronze_table_name}\")\n",
    "\n",
    "df_2024.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"delta.columnMapping.mode\", \"name\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(bronze_table_name)\n",
    "\n",
    "verified_count = spark.table(bronze_table_name).count()\n",
    "assert verified_count == records_2024, f\"Record count mismatch: {verified_count} != {records_2024}\"\n",
    "\n",
    "\n",
    "# After the assertions, add:\n",
    "print(f\"✓ Total raw records: {total_records:,}\")\n",
    "print(f\"✓ 2024 records: {records_2024:,}\")\n",
    "print(f\"✓ Null CVE IDs: {null_cve_ids}\")\n",
    "print(f\"✓ Unique CVE IDs: {unique_cve_ids}\")\n",
    "print(f\"✓ All assertions passed!\")\n",
    "\n",
    "# After saveAsTable, add:\n",
    "print(f\"\\n✓ Table verified: {verified_count:,} records in {bronze_table_name}\")\n",
    "\n",
    "# Show table details:\n",
    "spark.sql(f\"DESCRIBE DETAIL {bronze_table_name}\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3889d835-25c5-4044-8775-093bfc368718",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created cve_silver_core: 32,924 records\n✓ Created cve_silver_affected_products: 61,238 records\n\nSample from cve_silver_core:\n+--------------+-----------------------+-----------------------+-----------------------+---------+---------------+-------------+-----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|cve_id        |date_published         |date_reserved          |date_updated           |state    |cvss_base_score|cvss_severity|cvss_vector|description                                                                                                                                                                                                               |\n+--------------+-----------------------+-----------------------+-----------------------+---------+---------------+-------------+-----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|CVE-2024-22075|2024-01-05 00:00:00    |2024-01-05 00:00:00    |2025-06-05 16:18:14.218|PUBLISHED|NULL           |NULL         |NULL       |Firefly III (aka firefly-iii) before 6.1.1 allows webhooks HTML Injection.                                                                                                                                                |\n|CVE-2024-22900|2024-02-02 00:00:00    |2024-01-11 00:00:00    |2025-11-04 18:23:32.338|PUBLISHED|NULL           |NULL         |NULL       |Vinchin Backup & Recovery v7.2 was discovered to contain an authenticated remote code execution (RCE) vulnerability via the setNetworkCardInfo function.                                                                  |\n|CVE-2024-22148|2024-02-01 09:37:56.491|2024-01-05 11:18:25.467|2024-08-01 22:35:34.818|PUBLISHED|NULL           |NULL         |NULL       |Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting') vulnerability in WP Smart Editor JoomUnited allows Reflected XSS.This issue affects JoomUnited: from n/a through 1.3.3.\\n\\n          |\n|CVE-2024-22336|2024-02-17 15:45:35.951|2024-01-08 23:42:17.267|2024-08-01 22:43:34.457|PUBLISHED|NULL           |NULL         |NULL       |IBM QRadar Suite 1.10.12.0 through 1.10.17.0 and IBM Cloud Pak for Security 1.10.0.0 through 1.10.11.0 stores potentially sensitive information in log files that could be read by a local user.  IBM X-Force ID:  279976.|\n|CVE-2024-22442|2024-07-16 15:45:51.809|2024-01-10 15:24:39.967|2024-08-01 22:43:34.901|PUBLISHED|NULL           |NULL         |NULL       |The vulnerability could be remotely exploited to bypass authentication.                                                                                                                                                   |\n+--------------+-----------------------+-----------------------+-----------------------+---------+---------------+-------------+-----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nonly showing top 5 rows\n\nSample from cve_silver_affected_products:\n+--------------+---------------+----------------------+\n|cve_id        |vendor         |product               |\n+--------------+---------------+----------------------+\n|CVE-2024-22075|n/a            |n/a                   |\n|CVE-2024-22900|n/a            |n/a                   |\n|CVE-2024-22148|WP Smart Editor|JoomUnited            |\n|CVE-2024-22336|IBM            |QRadar Suite Software |\n|CVE-2024-22336|IBM            |Cloud Pak for Security|\n+--------------+---------------+----------------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "bronze_table_name = \"cve_bronze.records\"\n",
    "bronze_data = spark.table(bronze_table_name)\n",
    "\n",
    "core_cve_table = bronze_data.select(\n",
    "    F.col(\"cveMetadata.cveId\").alias(\"cve_id\"),\n",
    "    F.to_timestamp(F.col(\"cveMetadata.datePublished\")).alias(\"date_published\"),\n",
    "    F.to_timestamp(F.col(\"cveMetadata.dateReserved\")).alias(\"date_reserved\"),\n",
    "    F.to_timestamp(F.col(\"cveMetadata.dateUpdated\")).alias(\"date_updated\"),\n",
    "    F.col(\"cveMetadata.state\").alias(\"state\"),\n",
    "    \n",
    "    F.when(\n",
    "        F.size(F.col(\"containers.adp\")) > 0,\n",
    "        F.element_at(F.element_at(F.col(\"containers.adp\"), 1)[\"metrics\"], 1)[\"cvssV3_1\"][\"baseScore\"]\n",
    "    ).alias(\"cvss_base_score\"),\n",
    "    \n",
    "    F.when(\n",
    "        F.size(F.col(\"containers.adp\")) > 0,\n",
    "        F.element_at(F.element_at(F.col(\"containers.adp\"), 1)[\"metrics\"], 1)[\"cvssV3_1\"][\"baseSeverity\"]\n",
    "    ).alias(\"cvss_severity\"),\n",
    "    \n",
    "    F.when(\n",
    "        F.size(F.col(\"containers.adp\")) > 0,\n",
    "        F.element_at(F.element_at(F.col(\"containers.adp\"), 1)[\"metrics\"], 1)[\"cvssV3_1\"][\"vectorString\"]\n",
    "    ).alias(\"cvss_vector\"),\n",
    "    \n",
    "    F.when(\n",
    "        F.size(F.col(\"containers.cna.descriptions\")) > 0,\n",
    "        F.element_at(F.col(\"containers.cna.descriptions\"), 1)[\"value\"]\n",
    "    ).alias(\"description\")\n",
    ")\n",
    "\n",
    "core_table_name = \"cve_silver.core\"\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {core_table_name}\")\n",
    "\n",
    "core_cve_table.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(core_table_name)\n",
    "\n",
    "affected_products = bronze_data.select(\n",
    "    F.col(\"cveMetadata.cveId\").alias(\"cve_id\"),\n",
    "    F.explode_outer(F.col(\"containers.cna.affected\")).alias(\"affected_item\")\n",
    ").select(\n",
    "    F.col(\"cve_id\"),\n",
    "    F.col(\"affected_item.vendor\").alias(\"vendor\"),\n",
    "    F.col(\"affected_item.product\").alias(\"product\")\n",
    ")\n",
    "\n",
    "affected_products_clean = affected_products.filter(\n",
    "    F.col(\"vendor\").isNotNull() & F.col(\"product\").isNotNull()\n",
    ")\n",
    "\n",
    "affected_table_name = \"cve_silver.affected_products\"\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {affected_table_name}\")\n",
    "\n",
    "affected_products_clean.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(affected_table_name)\n",
    "\n",
    "spark.table(core_table_name).createOrReplaceTempView(\"cve_silver_core\")\n",
    "spark.table(affected_table_name).createOrReplaceTempView(\"cve_silver_affected_products\")\n",
    "\n",
    "\n",
    "# After creating core table, add:\n",
    "core_count = spark.table(\"cve_silver_core\").count()\n",
    "print(f\"✓ Created cve_silver_core: {core_count:,} records\")\n",
    "\n",
    "# After creating affected products table:\n",
    "products_count = spark.table(\"cve_silver_affected_products\").count()\n",
    "print(f\"✓ Created cve_silver_affected_products: {products_count:,} records\")\n",
    "\n",
    "# Show sample data:\n",
    "print(\"\\nSample from cve_silver_core:\")\n",
    "spark.table(\"cve_silver_core\").show(5, truncate=False)\n",
    "\n",
    "print(\"\\nSample from cve_silver_affected_products:\")\n",
    "spark.table(\"cve_silver_affected_products\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54bba890-17bf-443a-8846-b95c9ea48939",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+--------------+\n|month|vulnerability_count|avg_cvss_score|\n+-----+-------------------+--------------+\n|    1|               1134|          8.37|\n|    2|               1769|          7.06|\n|    3|               2616|          6.65|\n|    4|               3218|          6.74|\n|    5|               3348|          7.02|\n|    6|               2707|           7.0|\n|    7|               2877|          7.11|\n|    8|               2692|          7.57|\n|    9|               2408|          7.16|\n|   10|               3373|          7.24|\n|   11|               3760|          6.72|\n|   12|               3022|          6.93|\n+-----+-------------------+--------------+\n\n+-------------------+--------+--------+-----------+\n|avg_days_to_publish|min_days|max_days|median_days|\n+-------------------+--------+--------+-----------+\n|               38.8|       0|     396|         16|\n+-------------------+--------+--------+-----------+\n\n+--------------+-----+----------+\n|severity_level|count|percentage|\n+--------------+-----+----------+\n|      CRITICAL| 1028|      3.12|\n|          HIGH| 2394|      7.27|\n|        MEDIUM| 3118|      9.47|\n|           LOW|  143|      0.43|\n|       UNKNOWN|26241|     79.70|\n+--------------+-----+----------+\n\n+-----+------------+--------------+----------+\n|month|avg_severity|critical_count|high_count|\n+-----+------------+--------------+----------+\n|    1|        8.37|             0|         3|\n|    2|        7.06|            28|        65|\n|    3|        6.65|            38|        91|\n|    4|        6.74|            80|       186|\n|    5|        7.02|           124|       264|\n|    6|         7.0|            92|       174|\n|    7|        7.11|           100|       262|\n|    8|        7.57|           144|       256|\n|    9|        7.16|            91|       244|\n|   10|        7.24|           130|       280|\n|   11|        6.72|            97|       314|\n|   12|        6.93|           104|       255|\n+-----+------------+--------------+----------+\n\n+--------------------------+-------------------+-------------+\n|vendor                    |vulnerability_count|product_count|\n+--------------------------+-------------------+-------------+\n|n/a                       |5466               |318          |\n|Linux                     |2794               |3            |\n|Microsoft                 |1107               |278          |\n|Adobe                     |741                |30           |\n|Unknown                   |610                |398          |\n|SourceCodester            |557                |149          |\n|Google                    |546                |20           |\n|Apple                     |468                |13           |\n|Oracle Corporation        |366                |98           |\n|Cisco                     |278                |77           |\n|IBM                       |263                |93           |\n|Siemens                   |247                |582          |\n|code-projects             |235                |62           |\n|Dell                      |227                |119          |\n|Tenda                     |227                |41           |\n|Red Hat                   |227                |206          |\n|Samsung Mobile            |220                |33           |\n|Apache Software Foundation|213                |81           |\n|Mozilla                   |198                |6            |\n|Campcodes                 |191                |18           |\n|Ivanti                    |166                |29           |\n|Qualcomm, Inc.            |141                |1            |\n|SAP_SE                    |141                |99           |\n|itsourcecode              |136                |42           |\n|MediaTek, Inc.            |131                |100          |\n+--------------------------+-------------------+-------------+\n\n+------------------+----------+----------------+--------------+\n|vendor            |vuln_count|market_share_pct|cumulative_pct|\n+------------------+----------+----------------+--------------+\n|n/a               |5466      |16.79           |16.79         |\n|Linux             |2794      |8.58            |25.37         |\n|Microsoft         |1107      |3.40            |28.77         |\n|Adobe             |741       |2.28            |31.05         |\n|Unknown           |610       |1.87            |32.92         |\n|SourceCodester    |557       |1.71            |34.63         |\n|Google            |546       |1.68            |36.31         |\n|Apple             |468       |1.44            |37.75         |\n|Oracle Corporation|366       |1.12            |38.87         |\n|Cisco             |278       |0.85            |39.72         |\n+------------------+----------+----------------+--------------+\n\n+--------------------------+----------+--------------+--------------+--------------+\n|vendor                    |total_cves|avg_cvss_score|max_cvss_score|critical_count|\n+--------------------------+----------+--------------+--------------+--------------+\n|NEC Corporation           |10        |7.81          |9.8           |295           |\n|HP Inc.                   |15        |7.65          |9.8           |3             |\n|Mozilla                   |156       |7.44          |9.8           |94            |\n|FreeBSD                   |23        |7.43          |9.8           |4             |\n|n/a                       |3644      |7.41          |10.0          |810           |\n|Google                    |411       |7.38          |9.8           |15            |\n|Apache Software Foundation|113       |7.3           |9.8           |30            |\n|SonicWall                 |15        |6.92          |9.3           |1             |\n|Apple                     |369       |6.47          |10.0          |54            |\n|MediaTek, Inc.            |109       |6.45          |9.8           |10            |\n+--------------------------+----------+--------------+--------------+--------------+\n\n+---------------+-----------+--------------+--------------+-------------------+-----------------------+\n|total_cves_2024|scored_cves|avg_cvss_score|max_cvss_score|first_published    |last_published         |\n+---------------+-----------+--------------+--------------+-------------------+-----------------------+\n|32924          |6683       |7.02          |10.0          |2024-01-01 00:00:00|2024-12-31 23:09:24.244|\n+---------------+-----------+--------------+--------------+-------------------+-----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        MONTH(date_published) as month,\n",
    "        COUNT(*) as vulnerability_count,\n",
    "        ROUND(AVG(cvss_base_score), 2) as avg_cvss_score\n",
    "    FROM cve_silver_core\n",
    "    WHERE date_published IS NOT NULL\n",
    "    GROUP BY MONTH(date_published)\n",
    "    ORDER BY month\n",
    "\"\"\").show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        ROUND(AVG(DATEDIFF(date_published, date_reserved)), 1) as avg_days_to_publish,\n",
    "        MIN(DATEDIFF(date_published, date_reserved)) as min_days,\n",
    "        MAX(DATEDIFF(date_published, date_reserved)) as max_days,\n",
    "        PERCENTILE_APPROX(DATEDIFF(date_published, date_reserved), 0.5) as median_days\n",
    "    FROM cve_silver_core\n",
    "    WHERE date_reserved IS NOT NULL AND date_published IS NOT NULL\n",
    "\"\"\").show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        CASE \n",
    "            WHEN cvss_base_score >= 9.0 THEN 'CRITICAL'\n",
    "            WHEN cvss_base_score >= 7.0 THEN 'HIGH'\n",
    "            WHEN cvss_base_score >= 4.0 THEN 'MEDIUM'\n",
    "            WHEN cvss_base_score > 0.0 THEN 'LOW'\n",
    "            ELSE 'UNKNOWN'\n",
    "        END as severity_level,\n",
    "        COUNT(*) as count,\n",
    "        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) as percentage\n",
    "    FROM cve_silver_core\n",
    "    GROUP BY \n",
    "        CASE \n",
    "            WHEN cvss_base_score >= 9.0 THEN 'CRITICAL'\n",
    "            WHEN cvss_base_score >= 7.0 THEN 'HIGH'\n",
    "            WHEN cvss_base_score >= 4.0 THEN 'MEDIUM'\n",
    "            WHEN cvss_base_score > 0.0 THEN 'LOW'\n",
    "            ELSE 'UNKNOWN'\n",
    "        END\n",
    "    ORDER BY \n",
    "        CASE severity_level\n",
    "            WHEN 'CRITICAL' THEN 1\n",
    "            WHEN 'HIGH' THEN 2\n",
    "            WHEN 'MEDIUM' THEN 3\n",
    "            WHEN 'LOW' THEN 4\n",
    "            ELSE 5\n",
    "        END\n",
    "\"\"\").show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        MONTH(date_published) as month,\n",
    "        ROUND(AVG(cvss_base_score), 2) as avg_severity,\n",
    "        COUNT(CASE WHEN cvss_base_score >= 9.0 THEN 1 END) as critical_count,\n",
    "        COUNT(CASE WHEN cvss_base_score >= 7.0 AND cvss_base_score < 9.0 THEN 1 END) as high_count\n",
    "    FROM cve_silver_core\n",
    "    WHERE date_published IS NOT NULL\n",
    "    GROUP BY MONTH(date_published)\n",
    "    ORDER BY month\n",
    "\"\"\").show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        vendor,\n",
    "        COUNT(DISTINCT cve_id) as vulnerability_count,\n",
    "        COUNT(DISTINCT product) as product_count\n",
    "    FROM cve_silver_affected_products\n",
    "    WHERE vendor IS NOT NULL\n",
    "    GROUP BY vendor\n",
    "    ORDER BY vulnerability_count DESC\n",
    "    LIMIT 25\n",
    "\"\"\").show(25, truncate=False)\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    WITH vendor_counts AS (\n",
    "        SELECT \n",
    "            vendor,\n",
    "            COUNT(DISTINCT cve_id) as vuln_count\n",
    "        FROM cve_silver_affected_products\n",
    "        GROUP BY vendor\n",
    "    ),\n",
    "    total_vulns AS (\n",
    "        SELECT COUNT(DISTINCT cve_id) as total FROM cve_silver_affected_products\n",
    "    )\n",
    "    SELECT \n",
    "        vendor,\n",
    "        vuln_count,\n",
    "        ROUND(vuln_count * 100.0 / (SELECT total FROM total_vulns), 2) as market_share_pct,\n",
    "        ROUND(SUM(vuln_count * 100.0 / (SELECT total FROM total_vulns)) OVER (ORDER BY vuln_count DESC), 2) as cumulative_pct\n",
    "    FROM vendor_counts\n",
    "    ORDER BY vuln_count DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show(10, truncate=False)\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        p.vendor,\n",
    "        COUNT(DISTINCT p.cve_id) as total_cves,\n",
    "        ROUND(AVG(c.cvss_base_score), 2) as avg_cvss_score,\n",
    "        MAX(c.cvss_base_score) as max_cvss_score,\n",
    "        COUNT(CASE WHEN c.cvss_base_score >= 9.0 THEN 1 END) as critical_count\n",
    "    FROM cve_silver_affected_products p\n",
    "    JOIN cve_silver_core c ON p.cve_id = c.cve_id\n",
    "    WHERE p.vendor IS NOT NULL AND c.cvss_base_score IS NOT NULL\n",
    "    GROUP BY p.vendor\n",
    "    HAVING COUNT(DISTINCT p.cve_id) >= 10\n",
    "    ORDER BY avg_cvss_score DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show(10, truncate=False)\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(DISTINCT cve_id) as total_cves_2024,\n",
    "        COUNT(DISTINCT CASE WHEN cvss_base_score IS NOT NULL THEN cve_id END) as scored_cves,\n",
    "        ROUND(AVG(cvss_base_score), 2) as avg_cvss_score,\n",
    "        MAX(cvss_base_score) as max_cvss_score,\n",
    "        MIN(date_published) as first_published,\n",
    "        MAX(date_published) as last_published\n",
    "    FROM cve_silver_core\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ba3dc32-7656-4ea0-9bdc-853736bb455c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2025-11-16 17:44:22",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}